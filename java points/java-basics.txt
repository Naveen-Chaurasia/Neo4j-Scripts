in interface 
int x=10;(by default it will be final static)


Final-could not be changed by anyone.
Static-can be accessed without making object of it(directly using class)

class simple
{
Static String language="English"
}

class Test
{
main()
{

simple.langiage="Hindi"
print(simple.language);
}
}


>>always use final static varualbles for configuration
eg:Static final String USERNAME:Naveen

we can create refernce to an interface not objects
Class KafkaConsumer
Interface Producer


Producer:Inetrface in kafka api
Kafkaproducer:class in kafka api


Consumer:interface in kafka api
KAfkaConsumer:class  in kafka api

Lambdas:


List<String> list =new ArrayList<>();
list.add("red");

for(i..list.size())
{
list.get(index);
}


for( String color:list)
{
sys.out(color)
}


list.forEach(clor->System.out.println(color));

list.stream().filter(color->color.starttsWith("B")).forEach(color->System.out.println(color))


Build tools:
   downloading artifacts(jars/libararies/dependencies,plugins)
   making  abuild file (jar/war/ear)

   a.jar>>b.jar>>c.jar>>d.jar

   a.jar
      b.jar
         c.jar
            d.jar

Maven
Gradle

sbt-scala

for java-maven/gradle
Maven:
helps to download artifacts
helps todownload dpendent artifact
helps to compile .package java files


Testing:  
  Unit-JUNIT


Bigdata
  Problems
      storage
      processing

HAdoop
  hdfs-storage
  MApreduce-processing(for java)
  Hive-processing(on top of mapreduce based on sql)for those who know sql but not java

  Disk based computing

  spark--
        In memory based computing-reducing time
   Historiacal data
   streaming/Real-time/Livedata

Streaming technologies
----------------------
  Apache KAfka-for streaming dta for capturing /passing to respective dashboar
  Queue based system


bbefore kafka jms (java messging system was used)



Kafka-Architecture
--------------------
producer/sender --->broker/topic/message/partition---->consumer/record
                               Zookeeeper



Each topic is devided into some no. of  partitions.
>>>>Partioning improves sclaibility and throughput.
>>>>Each partition can be replicated across configurable no. of brokers--it provides fault tolerance

A topic partition is an orderes\d and immutable sequence of messages
>>>>Each message is assigned a unique sequential id known as offset.










////////for running kafka using docker
https://towardsdatascience.com/how-to-install-apache-kafka-using-docker-the-easy-way-4ceb00817d8b
https://levelup.gitconnected.com/running-kafka-on-docker-container-1a15b8d0b77c
save it in docker-compose.yml file


version: '3'

services:
  zookeeper:
    image: wurstmeister/zookeeper
    container_name: zookeeper
    ports:
      - "2181:2181"
  kafka:
    image: wurstmeister/kafka
    container_name: kafka
    ports:
      - "9092:9092"
    environment:
      KAFKA_ADVERTISED_HOST_NAME: localhost
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181       
  
///
then run
docker-compose -f docker-compose.yml up -d
docker ps
docker exec -it kafka /bin/sh
cd /opt/kafka_<version>/bin
kafka-topics.sh --create --zookeeper zookeeper:2181 --replication-factor 1 --partitions 1 --topic quickstart
kafka-console-producer.sh --topic quickstart --bootstrap-server localhost:9092
kafka-console-consumer.sh --topic quickstart --from-beginning --bootstrap-server localhost:9092
kafka-topics.sh -describe --bootstrap-server localhost:9092
////////////////////////////////////////

https://levelup.gitconnected.com/running-kafka-on-docker-container-1a15b8d0b77c

